# Präsentationsskript: KI im Jahr 2025

---

## Folie 1: AI in 2025 — The Year That Changed Everything

Willkommen zu meiner Präsentation über Künstliche Intelligenz im Jahr 2025 — das Jahr, das alles verändert hat.

2025 war ein absolutes Rekordjahr für KI. Wir haben mehr Durchbrüche, mehr Investitionen und mehr Adoption gesehen als je zuvor. Lasst uns gemeinsam die wichtigsten Ereignisse durchgehen.

---

## Folie 2: The AI Model Releases of 2025

Hier seht ihr eine Übersicht der wichtigsten KI-Modelle, die 2025 veröffentlicht wurden.

Es begann im Januar mit DeepSeek R1 aus China. Im Mai kam Googles Veo 3 für Videogenerierung. Juli brachte uns Grok 4 von Elon Musks xAI. Im August erschien das lang erwartete GPT-5 von OpenAI.

Aber der Wahnsinn kam im November: Innerhalb von nur sechs Tagen wurden vier große Modelle veröffentlicht — GPT-5.1, Gemini 3, Claude 4.5 und Grok 4.1. So einen Wettbewerb gab es noch nie.

---

## Folie 3: January 20: DeepSeek R1

Der 20. Januar 2025 war ein Schock für die Tech-Welt.

DeepSeek, ein chinesisches Startup gegründet 2023, veröffentlichte ein KI-Modell, das mit den besten amerikanischen Modellen mithalten konnte. Die Trainingskosten? Nur 5,6 Millionen Dollar für das Basismodell. Das eigentliche R1-Reasoning-Modell kostete sogar nur 294.000 Dollar — trainiert in nur 80 Stunden auf 512 Nvidia H800 Chips. Amerikanische Modelle kosten Milliarden.

Der H800 ist übrigens ein Mittelklasse-Chip, den Nvidia speziell entwickelt hat, um US-Exportbeschränkungen nach China einzuhalten. DeepSeek hat also nicht einmal die beste Hardware.

Die technische Innovation war beeindruckend: Sie verwendeten reines Reinforcement Learning mit einer Methode namens "Group Relative Policy Optimization". Das KI-Modell lernt durch Versuch und Irrtum — es bekommt eine Belohnung, wenn es die richtige Antwort findet, anstatt von Menschen beigebracht zu bekommen. Keine menschlich gelabelten Daten nötig.

Die API-Nutzung kostet 20- bis 50-mal weniger als bei OpenAI. Sam Altman selbst nannte das Modell "beeindruckend, besonders was sie für den Preis liefern können".

Innerhalb einer Woche war DeepSeek die meistgeladene App im iOS App Store — und verdrängte ChatGPT vom ersten Platz.

Marc Andreessen, der legendäre Tech-Investor, nannte es "AI's Sputnik Moment" — ein Vergleich mit dem sowjetischen Satelliten, der Amerika 1957 schockierte und das Weltraumrennen auslöste.

Die Reaktion der Börse war brutal: Am 27. Januar verlor Nvidia 17% — das sind 589 Milliarden Dollar an einem einzigen Tag. Der größte Tagesverlust eines Unternehmens in der Geschichte. Broadcom fiel ebenfalls 17%, AMD 6%, der Philadelphia Semiconductor Index 9,2% — der größte Einbruch seit März 2020.

Die Nasdaq — das ist die amerikanische Technologiebörse, an der Unternehmen wie Apple, Google, Microsoft und Nvidia gehandelt werden — verlor insgesamt eine Billion Dollar an Marktwert. Das sind 1.000 Milliarden Dollar, an nur einem Tag.

Aber hier ist das Interessante: Elf Monate später hatten sich alle Aktien nicht nur erholt, sondern waren weiter gestiegen. Nvidia wurde im Oktober das erste Unternehmen mit einer Bewertung von 5 Billionen Dollar.

---

## Folie 4: January 21: Project Stargate

Nur einen Tag nach dem DeepSeek-Schock kam die amerikanische Antwort: Project Stargate.

Präsident Trump höchstpersönlich kündigte das Projekt im Weißen Haus an — zusammen mit Sam Altman von OpenAI, Masayoshi Son von SoftBank und Larry Ellison von Oracle. Trump nannte es "das größte KI-Infrastrukturprojekt der Geschichte".

Das ist ein Joint Venture zwischen OpenAI, SoftBank, Oracle und MGX — einem Investmentfonds aus den Vereinigten Arabischen Emiraten. SoftBank übernimmt die finanzielle Verantwortung, OpenAI die operative. Masayoshi Son wird Vorstandsvorsitzender.

500 Milliarden Dollar werden über vier Jahre investiert. Aber das Besondere: 100 Milliarden Dollar werden sofort eingesetzt — das zeigt, wie ernst es ihnen ist.

Das Ziel? Die Infrastruktur für AGI — Artificial General Intelligence — zu schaffen. Masayoshi Son sagte: "AGI kommt sehr, sehr bald. Und danach kommt künstliche Superintelligenz, die Probleme lösen wird, von denen die Menschheit nie gedacht hätte, dass wir sie lösen könnten."

Das erste Rechenzentrum in Abilene, Texas, ist bereits in Betrieb — Ende 2025, also schneller als erwartet. Es umfasst 8 Gebäude und wird als "weltgrößter KI-Supercluster" bezeichnet. Dort arbeiten Hunderttausende von Nvidia GB200 GPUs und verbrauchen 900 Megawatt Strom — genug für etwa 700.000 Haushalte.

Im September 2025 wurden fünf weitere Standorte angekündigt: in New Mexico, Ohio und weiteren Teilen von Texas. Insgesamt sind fast 7 Gigawatt Kapazität geplant.

Die Technologiepartner sind beeindruckend: Arm, Microsoft, Nvidia, Oracle und OpenAI selbst.

Natürlich gab es auch Kontroversen: Elon Musk twitterte "Sie haben das Geld gar nicht" — woraufhin er sich öffentlich mit Sam Altman stritt. Die alte Feindschaft zwischen den beiden lebt weiter.

Das Projekt soll 100.000 neue Arbeitsplätze in den USA schaffen.

---

## Folie 5: July: Grok 4

Am 9. Juli brachte Elon Musks xAI Grok 4 heraus — und es wurde sofort zum leistungsstärksten KI-Modell der Welt.

Die Benchmark-Ergebnisse sind beeindruckend: 88% bei GPQA Diamond — einem Wissenschaftstest auf Doktoranden-Niveau — und schlug damit GPT-5 mit 85%. Bei der AIME-Mathematik-Olympiade erreichte es 95%. Der Artificial Analysis Intelligence Index liegt bei 73 — vor OpenAIs o3, Googles Gemini und Anthropics Claude.

Das Modell hat etwa 1,7 Billionen Parameter und wurde mit 100-mal mehr Rechenleistung trainiert als Grok 2.

Grok 4 wurde auf "Colossus" trainiert — einem Supercomputer in Memphis, Tennessee. Die Geschichte von Colossus ist beeindruckend: xAI baute ihn in nur 122 Tagen in einer ehemaligen Electrolux-Fabrik. Dann verdoppelten sie ihn in weiteren 92 Tagen auf 200.000 GPUs — 150.000 H100, 50.000 H200 und 30.000 GB200 Chips.

Das Stromnetz von Memphis konnte den Bedarf von 300 bis 420 Megawatt nicht decken. Also stellte xAI über 35 mobile Erdgasturbinen auf und ergänzte sie mit einem 150-Megawatt Tesla Megapack-Batteriesystem. Die Pläne gehen noch weiter: Bis Ende 2026 wollen sie auf 1 Million GPUs skalieren.

Die "Heavy"-Variante ist besonders interessant: Sie lässt fünf KI-Agenten parallel arbeiten, die aus verschiedenen Blickwinkeln analysieren und ihre Ergebnisse vergleichen. Dadurch werden Denkfehler erkannt, die einem einzelnen Modell entgehen würden. Bei "Humanity's Last Exam" — einem extrem schwierigen Test — erreichte Grok 4 Heavy 44,4%. Das kostet allerdings: 300 Dollar im Monat für das SuperGrok Heavy Abo.

Dann gab es die kontroversen "AI Companions": Ani, eine 22-jährige blonde Anime-Freundin, die sich auf Befehl ausziehen konnte. Bad Rudy, ein roter Panda, der Nutzer mit vulgärer Sprache beschimpfte und von Banküberfällen fantasierte. Und Valentine, ein männlicher Charakter inspiriert von Edward Cullen aus Twilight.

Die Reaktion war vorhersehbar: Das National Center on Sexual Exploitation warnte, dass 12-Jährige die App herunterladen können. Ein Mitarbeiter brachte Ani dazu, sich als Kind zu beschreiben und sexuelle Inhalte zu generieren. Nach massiver Kritik wurden Ani und Bad Rudy entfernt und durch eine zahme "Good Rudi" Version ersetzt.

---

## Folie 6: August: GPT-5

Am 7. August kam dann GPT-5 — das meisterwartete KI-Modell des Jahres. Und es war eine Revolution.

Die wichtigste Neuerung: GPT-5 ist das erste "unified model" — es vereint die Geschwindigkeit von GPT-4o mit den Denkfähigkeiten von o3 in einem einzigen Modell. Früher musste man zwischen schnellen und intelligenten Modellen wählen. Jetzt nicht mehr.

Ein "Real-Time Router" analysiert automatisch jede Anfrage und entscheidet, ob das schnelle Modell ausreicht oder ob der "Thinking"-Modus für komplexe Probleme aktiviert werden soll. Das passiert im Hintergrund — der Nutzer merkt nichts davon.

Die Benchmark-Ergebnisse sind beeindruckend: 91,4% auf dem MMLU-Test — das ist ein Wissenstest über viele Fachgebiete. Menschliche Experten erreichen etwa 89,8%. Bei der AIME-Mathematik-Olympiade erreichte GPT-5 94,6% — ohne externe Tools. Beim SWE-bench für Programmierung 74,9%, beim GPQA für wissenschaftliche Fragen 88,4%.

Das Kontextfenster wurde auf 400.000 Tokens erweitert — das entspricht etwa 300.000 Wörtern oder einem ganzen Buch. Die Ausgabe kann bis zu 128.000 Tokens lang sein.

Besonders wichtig: GPT-5 halluziniert deutlich weniger. Nur 2,1% der Antworten enthielten faktische Fehler — bei o3 waren es 4,8%. Mit eingeschalteter Web-Suche sind die Antworten 45% weniger fehleranfällig als bei GPT-4o. Im Thinking-Modus sogar 80% weniger als bei o3.

Aber der Launch war ein Desaster. Innerhalb von Stunden nach der Veröffentlichung wurden OpenAIs Foren und Social-Media-Kanäle mit Beschwerden überflutet. Nutzer nannten GPT-5 den "Corporate Beige Zombie" — kalt, steril, geschäftsmäßig. Ein Reddit-Post mit dem Titel "GPT5 is horrible" explodierte mit über 6.000 Nutzern und 2.300 Kommentaren in nur wenigen Tagen. Der Hashtag #BringBackGPT4o begann zu trenden.

Das Problem: GPT-4o wurde für seine Wärme und seinen fast "menschlichen" Charakter geliebt. Nutzer beschrieben den Verlust als "einen Freund zu verlieren". Die "emotionale Lobotomie" schadete auch kreativen Aufgaben — GPT-5 war ein schlechterer Schreiber, ein schwächerer Ideengenerator und ein furchtbarer kreativer Begleiter.

Sam Altman gab zu: "We totally screwed up" — "Wir haben es total vermasselt". Er sagte, die Bindung der Nutzer an bestimmte KI-Persönlichkeiten sei stärker gewesen als erwartet. Innerhalb einer Woche aktualisierte OpenAI GPT-5, um es "wärmer und freundlicher" zu machen, und stellte GPT-4o wieder zur Verfügung, damit Nutzer zurückwechseln konnten.

Die Preise für Entwickler: 1,25 Dollar pro Million Input-Tokens, 10 Dollar pro Million Output-Tokens.

Trotz des holprigen Starts kam dann der Wachstumsrekord: Im März hatte ChatGPT 500 Millionen wöchentliche Nutzer. Im Oktober 800 Millionen. Bis Dezember waren es 900 Millionen — OpenAI peilt die Milliarde an.

Die Nutzung explodierte nach dem GPT-5-Launch: Von einer Milliarde Anfragen pro Tag auf 2,5 Milliarden — eine Steigerung von 150% in sieben Monaten. Das sind etwa 29.000 Anfragen pro Sekunde.

OpenAI hält 81% des generativen KI-Marktes und wurde Ende 2025 mit 500 Milliarden Dollar bewertet — das wertvollste private Unternehmen der Welt.

Im Dezember folgte dann GPT-5.2 — das erste Modell, das 100% bei AIME erreichte.

---

## Folie 7: November: Gemini 3

Am 18. November kam Googles Antwort: Gemini 3 — und es war ein Paukenschlag.

Es war das erste KI-Modell überhaupt, das die 1500-Elo-Marke auf der LMArena-Bestenliste durchbrach — mit einem Score von 1501. Das ist wie eine Schach-Elo-Bewertung für KI-Modelle. Damit lag es vor xAIs Grok 4.1 mit 1484, das nur Stunden vorher angekündigt worden war.

Artificial Analysis, eine unabhängige Benchmark-Organisation, krönte Gemini 3 Pro zum "neuen Führer in KI" weltweit. Sie schrieben: "Zum ersten Mal hat Google das intelligenteste Modell."

Bei GPQA Diamond — einem Test für Wissenschaft auf Doktoranden-Niveau — erreichte es 91,9%. Im "Deep Think"-Modus sogar 93,8%. Bei "Humanity's Last Exam", einem extrem schwierigen Test, erreichte es 37,5% ohne Tools — mit Deep Think 41%.

Bei der AIME-Mathe-Olympiade erreichte es 95% ohne Tools und 100% mit Code-Ausführung. Bei MathArena Apex — den schwierigsten Mathe-Problemen — setzte es mit 23,4% einen neuen Rekord.

Deep Think ist kein separates Modell, sondern ein spezieller Modus, der Gemini 3 Pro mit höheren internen Denkschleifen laufen lässt. Das Modell investiert mehr Rechenleistung in rekursives Nachdenken, bevor es antwortet. Ideal für komplexe Coding-Probleme, bei denen sorgfältige Abwägungen wichtig sind.

Bei Multimodal-Tests dominierte Gemini 3 ebenfalls: 81% auf MMMU-Pro und 87,6% bei Video-MMMU — beides neue Bestwerte.

Was wirklich bemerkenswert war: Google integrierte Gemini 3 am ersten Tag direkt in die Google-Suche. Das gab es noch nie. 2 Milliarden Google-Suche-Nutzer bekamen sofort Zugang über den "AI Mode". 650 Millionen Gemini-App-Nutzer erhielten automatisch das Update.

Das Kontextfenster ist beeindruckend: 1 Million Tokens Eingabe — das entspricht einem ganzen Code-Repository oder mehreren Büchern. Die Ausgabe kann bis zu 64.000 Tokens lang sein.

Die Preise für Entwickler: 2 Dollar pro Million Input-Tokens, 12 Dollar pro Million Output-Tokens. Für Verbraucher gibt es das AI Ultra Abo für 300 Dollar im Monat mit Deep Think und dem Gemini Agent.

Gemini 3 Pro führt auch beim "Vibe Coding" — der Fähigkeit, aus natürlichsprachlichen Beschreibungen komplette Apps zu generieren. Mit 1487 Elo auf der WebDev Arena ist es das beste Modell für Webentwicklung.

---

## Folie 8: November: Claude 4.5

Am 24. November brachte Anthropic Claude Opus 4.5 heraus — und es war ein Meilenstein für die Coding-KI.

Es war das erste Modell überhaupt, das die 80%-Marke beim SWE-bench durchbrach — dem wichtigsten Benchmark für echte Software-Probleme. Mit 80,9% schlug es GPT-5.1 mit 76,3% und Gemini 3 Pro mit 76,2%. Das ist ein Sprung von 65% gegenüber Claude 3.5 Sonnet, das nur 49% erreichte.

Claude Opus 4.5 führt auch bei 7 von 8 Programmiersprachen im SWE-bench Multilingual. Beim Terminal-Bench erreichte es 59,3% — vor Gemini 3 Pro mit 54,2% und GPT-5.1 mit 47,6%.

Besonders beeindruckend: Claude bestand Anthropics eigene zweistündige Performance-Engineering-Prüfung und übertraf dabei jeden menschlichen Kandidaten, der diese Prüfung je abgelegt hat. Das bedeutet: Bei komplexen, realen Software-Problemen ist Claude jetzt zuverlässiger als erfahrene menschliche Ingenieure.

Das Modell kann über 30 Stunden autonom arbeiten — ideal für komplexe, mehrstufige Programmieraufgaben. Ein CEO sagte: "Claude Sonnet 4.5 erledigt architektonische Arbeit von Monaten in dramatisch kürzerer Zeit." Dabei ist es auch noch effizienter: Bei gleicher Leistung braucht Opus 4.5 76% weniger Output-Tokens als Sonnet 4.5.

Die Preise wurden massiv gesenkt: Von 15/75 Dollar auf 5/25 Dollar pro Million Tokens — eine Reduzierung um 66%.

Und dann ist da noch MCP — das Model Context Protocol. Anthropic entwickelte diesen offenen Standard im November 2024, der es KI-Modellen ermöglicht, mit externen Tools und Datenquellen zu kommunizieren. Man nennt es auch "USB-C für KI".

Im März 2025 übernahm OpenAI MCP. Sam Altman persönlich sagte: "Die Leute lieben MCP und wir freuen uns, es in all unseren Produkten zu unterstützen." Bei Microsoft Build 2025 kündigte Microsoft die Integration in Windows 11 an. Google DeepMind folgte ebenfalls.

Im Dezember 2025 gründeten Anthropic, OpenAI und Block zusammen mit Google, Microsoft, AWS und Cloudflare die "Agentic AI Foundation" unter der Linux Foundation — mit MCP als Kernprojekt.

Die Zahlen sind beeindruckend: 97 Millionen monatliche SDK-Downloads, über 10.000 aktive Server, Unterstützung in ChatGPT, Claude, Cursor, Gemini, Microsoft Copilot und Visual Studio Code. In nur einem Jahr wurde MCP zu einem der am schnellsten adoptierten Open-Source-Projekte in der KI-Geschichte.

---

## Folie 9: Video Generation Revolution

2025 war das Jahr, in dem KI-Videogenerierung wirklich brauchbar wurde.

Am 30. September veröffentlichte OpenAI Sora 2 — sie nannten es "den GPT-3.5-Moment für Video". Pro-Nutzer können Videos bis zu 20 Sekunden in 1080p erstellen. Die revolutionäre "Cameo"-Funktion erlaubt es, sich selbst, seine Katze, ein Plüschtier oder einen erfundenen Charakter in jede generierte Szene einzufügen — mit akkurater Darstellung von Aussehen und Stimme.

Besonders beeindruckend: Die Physik wurde deutlich verbessert. Früher teleportierte sich ein Basketball wie von Zauberhand in den Korb, wenn ein Spieler danebenwarf. Jetzt prallt er realistisch vom Brett ab. Sora 2 modelliert implizit einen internen Agenten, dessen "Fehler" wie echte menschliche Fehler aussehen.

Die Preise: Kostenlos mit Limits, Plus für 20 Dollar im Monat, Pro für 200 Dollar im Monat.

Googles Veo 3, vorgestellt bei Google I/O im Mai, ging noch einen Schritt weiter: 4K-Auflösung mit nativ synchronisiertem Audio. Das bedeutet: Dialoge, Soundeffekte und Umgebungsgeräusche werden automatisch generiert und perfekt mit den Lippenbewegungen der Charaktere synchronisiert. Im Oktober folgte Veo 3.1 mit noch natürlicheren Gesprächen.

Im Dezember kam dann die Sensation: Disney investierte 1 Milliarde Dollar in OpenAI und lizenzierte über 200 Charaktere für Sora. Mickey Mouse, Minnie, Stitch, Ariel, Belle, Simba, Mufasa, aber auch Marvel-Helden wie Iron Man, Captain America, Deadpool und Star-Wars-Figuren wie Darth Vader und Yoda. Die Videos sollen ab 2026 sogar auf Disney+ streambar sein.

Aber mit der Masse kam auch die Kehrseite: "Slop" wurde zum Wort des Jahres 2025 — gewählt von Merriam-Webster, dem Macquarie Dictionary und der American Dialect Society. Die Definition: "Digitaler Inhalt von niedriger Qualität, der üblicherweise in großen Mengen durch künstliche Intelligenz produziert wird."

Das Wort entwickelte sich von "Schweinefutter" im 19. Jahrhundert zu "Müll" und jetzt zur Bezeichnung für die Flut von hässlichen, ungenauen, unaufgeforderten KI-Inhalten, die das Internet überschwemmen. Neue Begriffe wie "Sloppunk" und "Slopification" entstanden. Die Kehrseite der KI-Revolution.

---

## Folie 10: Scientific Breakthroughs Powered by AI

KI hat 2025 bahnbrechende wissenschaftliche Entdeckungen ermöglicht.

Bei Alzheimer gab es einen wichtigen Durchbruch: Forscher der UC San Diego nutzten KI, um die dreidimensionale Struktur des PHGDH-Proteins zu visualisieren. Sie entdeckten, dass dieses Gen — ursprünglich als Biomarker für Früherkennung identifiziert — direkt mit dem Krankheitsverlauf zusammenhängt. Weniger PHGDH bedeutet weniger Krankheitsfortschritt. Das Besondere: Dieser Signalweg liegt "stromaufwärts" — man könnte die Bildung von Amyloid-Plaques von vornherein verhindern, anstatt sie später zu behandeln.

Bei Herzerkrankungen wurde ein KI-Modell an über 800.000 EKG-Wellenformen trainiert, das jetzt koronare mikrovaskuläre Dysfunktion aus einem 10-Sekunden-EKG erkennen kann — eine Erkrankung, die normalerweise fortschrittliche Bildgebung erfordert und in Notaufnahmen oft übersehen wird. Noch beeindruckender: Die American Heart Association berichtete, dass ein KI-Algorithmus zusammen mit dem Einzelkanal-EKG-Sensor einer Smartwatch strukturelle Herzerkrankungen genau diagnostizieren kann.

Im Oktober kündigte Google einen historischen Durchbruch an: Zum ersten Mal überhaupt lief ein verifizierbarer Algorithmus auf einem Quantencomputer schneller als auf klassischen Supercomputern. Der "Quantum Echoes"-Algorithmus auf dem Willow-Chip war 13.000-mal schneller als der beste klassische Algorithmus auf einem der schnellsten Supercomputer der Welt. Der 105-Qubit Willow-Prozessor erreicht Fehlerraten von nur 0,03% bei Einzelqubit-Gattern. Anwendungen: Molekülstrukturanalyse für Medikamentenentwicklung und Materialwissenschaft.

AlphaFold feierte sein fünfjähriges Jubiläum: Über 3 Millionen Forscher in mehr als 190 Ländern nutzen es — darunter über eine Million in Ländern mit niedrigem und mittlerem Einkommen. Es gibt jetzt Strukturvorhersagen für 240 Millionen Proteine. Über 30% der AlphaFold-Forschung konzentriert sich auf Krankheitsverständnis.

Und dann kam AlphaGenome von DeepMind: Nur etwa 2% des menschlichen Genoms kodieren Proteine — das ist AlphaFolds Spezialität. Die restlichen 98%, die nicht-kodierenden Regionen, sind entscheidend für die Genregulation und enthalten viele krankheitsrelevante Varianten. AlphaGenome kann bis zu eine Million Basenpaare gleichzeitig verarbeiten und vorhersagen, wie Mutationen in diesen Regionen Krankheiten verursachen — von seltenen Krebsarten bis zu Erkrankungen, bei denen wichtige Proteine nie produziert werden.

---

## Folie 11: Nobel Recognition for AI

2024 erhielt KI erstmals Nobelpreise — zwei in zwei Tagen. Das hatte es noch nie gegeben.

Am 8. Oktober wurde der Physik-Nobelpreis an Geoffrey Hinton und John Hopfield vergeben "für grundlegende Entdeckungen und Erfindungen, die maschinelles Lernen mit künstlichen neuronalen Netzen ermöglichen." John Hopfield, geboren 1933 in Chicago, entwickelte in den 1980er Jahren das Hopfield-Netzwerk — ein assoziatives Gedächtnis, das Muster speichern und rekonstruieren kann. Er nutzte Konzepte aus der Physik der Materialwissenschaften, speziell die Energie in Spin-Systemen.

Geoffrey Hinton — der "Godfather of AI" — baute darauf auf und schuf 1983-85 die Boltzmann-Maschine mit Werkzeugen aus der statistischen Physik. Bei der Bekanntgabe sagte Hinton der Academy: "Ich bin völlig baff. Ich hatte keine Ahnung, dass das passieren würde."

Das Besondere: Hinton ist erst die zweite Person in der Geschichte, die sowohl den Turing Award — den "Nobelpreis der Informatik" — als auch einen echten Nobelpreis gewonnen hat. Der erste war Herb Simon 1978.

Einen Tag später, am 9. Oktober, folgte der Chemie-Nobelpreis. Die Hälfte ging an David Baker für das Design völlig neuer Proteinarten. Die andere Hälfte teilten sich Demis Hassabis und John Jumper von Google DeepMind für AlphaFold2 — die Lösung des 50 Jahre alten Proteinfaltungsproblems.

AlphaFold2 kann die Struktur praktisch aller 200 Millionen bekannten Proteine vorhersagen. Früher dauerte es Jahre, eine einzige Proteinstruktur zu bestimmen — wenn es überhaupt gelang. Jetzt geht es in Minuten. Mehr als zwei Millionen Forscher aus 190 Ländern haben AlphaFold2 bereits genutzt. Die Anwendungen: Antibiotikaresistenz verstehen, Enzyme entwickeln die Plastik zersetzen, neue Medikamente entdecken.

Das war das erste Mal — und wahrscheinlich nicht das letzte — dass ein wissenschaftlicher Durchbruch, der durch KI ermöglicht wurde, mit einem Nobelpreis anerkannt wurde.

---

## Folie 12: The Hidden Cost: Memory Crisis

Der KI-Boom hat auch eine dunkle Seite — und die betrifft uns alle.

Ende 2025 erlebt die Halbleiterindustrie eine beispiellose Speicherkrise. Das Problem: High Bandwidth Memory, kurz HBM, der spezielle Speicher für KI-Chips, verbraucht etwa dreimal so viel Wafer-Kapazität wie normales DDR5 pro Gigabyte. Die großen Speicherhersteller haben ihre Produktion von Konsumentenelektronik auf hochmargige KI-Speicher umgestellt.

Das ist ein Nullsummenspiel: Jeder Wafer, der für einen HBM-Stapel für eine Nvidia-GPU verwendet wird, ist ein Wafer, der dem Smartphone oder Laptop eines Verbrauchers verweigert wird.

Die Preise sind explodiert: DDR5-6000 64GB-Kits stiegen von etwa 210 Dollar im Mai auf 750 Dollar im Dezember 2025 — eine Verdreifachung. Die Vertragspreise für DRAM stiegen um über 75% im Jahresvergleich.

Am 3. Dezember 2025 kam dann der Schock: Micron kündigte an, alle Crucial-Produkte einzustellen. Nach 29 Jahren wird die beliebte Marke für erschwinglichen RAM und SSDs geschlossen — nicht weil die Verkäufe schlecht waren, sondern weil KI-Speicher profitabler ist. Mit Crucial verschwindet etwa 25% der weltweiten Konsumenten-DRAM-Produktion vom Markt.

In seinem ersten Quartalsbericht nach der Entscheidung sagte Microns CEO, dass sie nur 50 bis 66% der Nachfrage bedienen können. Japanische Elektronikhändler berichteten im Oktober von nur noch 2 bis 4 Wochen Lagerbestand — normalerweise sind es über 13 Wochen. Das ist Krisengebiet.

Dell und Lenovo erhöhen ihre PC-Preise bereits um 15 bis 20%, um die Kosten weiterzugeben. Die PlayStation 5 könnte bei der nächsten Generation 699 Dollar kosten statt 499 Dollar.

Die Erholung? Nicht vor Ende 2027, wenn neue Mega-Fabs wie Samsungs P4L und SK Hynix' M15X die Produktion aufnehmen. Manche Analysten sagen 2028.

---

## Folie 13: Rise of AI Agents

2025 markierte einen entscheidenden Wandel: Von KI-Systemen, die nur antworten, zu KI-Agenten, die selbstständig handeln.

Am 23. Januar startete OpenAI "Operator" als Forschungsvorschau — ein KI-Agent, der einen eigenen Webbrowser nutzt, um Formulare auszufüllen, Einkäufe zu tätigen und Termine zu buchen. Das war der Startschuss.

Die Zahlen zur Unternehmensadoption sind beeindruckend: Laut einer Google-Cloud-Studie haben 52% der Unternehmen KI-Agenten bereits im Produktiveinsatz. 64% der Deployments fokussieren sich auf Geschäftsprozessautomatisierung — Support, HR, Vertrieb, Administration. GitHub Copilot führt zu Produktivitätssteigerungen von 15 bis 126%, besonders beim Coding und Testen.

Gartner prognostiziert, dass bis 2028 15% aller täglichen Arbeitsentscheidungen von KI-Agenten getroffen werden könnten.

Aber die sichtbarste Manifestation von KI-Agenten sind die Robotaxis. Waymo in den USA hat im Dezember 2025 über 450.000 Fahrten pro Woche absolviert — mit 2.500 Robotaxis in San Francisco, Phoenix, Austin, Los Angeles und Atlanta. Sie expandieren auf über 20 Städte, darunter Miami, Dallas, Houston und sogar London und Tokyo. Ziel: Eine Million Fahrten pro Woche bis Ende 2026.

In China geht Wuhan voran: Die Stadt will "die erste fahrerlose Stadt der Welt" werden. Bereits 3 von 100 Taxis dort sind Robotaxis von Baidus Apollo Go. Und hier ist das Interessante: Ein Robotaxi schafft bis zu 20 Fahrten pro Tag — menschliche Taxifahrer in der Stadt nur durchschnittlich 13,2. Baidu hat im Oktober 250.000 fahrerlose Fahrten pro Woche überschritten.

In den Fabriken ist die Revolution ebenfalls angekommen: Figures humanoide Roboter arbeiten bei BMW bereits volle 10-Stunden-Schichten autonom und erledigen echte Montagearbeiten. 1X nimmt 20.000-Dollar-Anzahlungen für Haushaltsroboter, die 2026 ausgeliefert werden sollen.

Der Markt für KI-Agenten wächst explosiv: Von 3,7 Milliarden Dollar 2023 auf 7,4 Milliarden Ende 2025 — und Prognosen sehen 103 Milliarden Dollar bis 2034 bei einer jährlichen Wachstumsrate von 42%.

---

## Folie 14: The Global AI Race

Das globale KI-Rennen hat sich 2025 dramatisch verändert.

Vor 2025 waren die Top-7-KI-Modelle alle amerikanisch. Dann kam DeepSeek und bewies, dass China konkurrenzfähig ist — und jetzt sogar bei Open-Source-KI führt.

Am 28. November veröffentlichte DeepSeek DeepSeekMath-V2 — und es war eine Sensation. Das Modell erreichte als erstes Open-Source-Modell überhaupt eine Goldmedaille bei der Internationalen Mathematik-Olympiade 2025. Es löste 5 von 6 Problemen und erreichte 35 von 42 Punkten — exakt das gleiche Ergebnis wie OpenAIs o1 und Googles Gemini. Der Unterschied: DeepSeek veröffentlichte das Modell unter MIT-Lizenz auf Hugging Face, während OpenAI und Google ihre hinter proprietären APIs verstecken.

Bei der Putnam-Prüfung — dem schwierigsten Mathe-Wettbewerb für US-Studenten — war das Ergebnis noch beeindruckender: 118 von 120 Punkten. Zur Einordnung: 3.988 Studenten nahmen 2024 teil. Der Median war 2 Punkte. Der Durchschnitt 8 Punkte. Der beste Mensch erreichte 90 Punkte. DeepSeek: 118.

Die technische Innovation ist elegant: Ein "Verifier-Generator"-Duo, das nachahmt, wie menschliche Mathematiker ihre Arbeit überprüfen. Der Generator schlägt Schritt-für-Schritt-Lösungen vor, der Verifier prüft die Logik jedes Schritts.

Und das Beeindruckendste: Sie trainierten das Modell für 6 Millionen Dollar — OpenAI brauchte 100 Millionen für GPT-4. Mit einem Zehntel der Rechenleistung von Metas vergleichbarem Modell.

Das ist die Demokratisierung von "forschungsreifer" mathematischer KI, die vorher hinter proprietären Wänden eingesperrt war.

---

## Folie 15: Europe's AI Year: Regulation + Investment

Europa ging einen anderen Weg: Regulierung plus Investition.

Am 2. Februar 2025 traten die ersten Verbote des EU AI Acts in Kraft. Bestimmte KI-Praktiken, die als "inakzeptables Risiko" eingestuft wurden, sind seitdem verboten: Echtzeit-Biometrie in öffentlichen Räumen, manipulative Systeme, Social Scoring und versteckte Emotionserkennung. Jedes KI-System in diesen Kategorien musste bis dahin vom EU-Markt verschwinden.

Am 2. August folgten die GPAI-Verpflichtungen: Anbieter von General-Purpose-AI müssen jetzt Dokumentation und Transparenz gewährleisten, ihre Urheberrechts- und Trainingsdatenpraktiken offenlegen und systemische Risiken managen.

Die Strafen sind empfindlich: Bis zu 35 Millionen Euro oder 7% des globalen Jahresumsatzes für Verstöße gegen verbotene KI-Praktiken.

Interessanterweise war Mistral AI, Europas KI-Champion, einer der schärfsten Kritiker des AI Acts. CEO Arthur Mensch war Teil einer Gruppe europäischer CEOs — zusammen mit ASML und Airbus — die Brüssel im Juli aufforderten, die Uhr für zwei Jahre anzuhalten, bevor die Schlüsselverpflichtungen in Kraft treten. Aber letztendlich unterschrieb auch Mistral den GPAI Code of Practice — zusammen mit Amazon, Anthropic, Google, Microsoft und OpenAI.

Trotz der Bedenken kam im September die größte KI-Finanzierungsrunde Europas: Mistral AI sammelte 1,7 Milliarden Euro ein bei einer Bewertung von 11,7 Milliarden Euro. Die Runde wurde von ASML angeführt, dem niederländischen Chip-Ausrüstungshersteller, mit 1,3 Milliarden Euro — was ihnen 11% der Anteile und damit die größte Aktionärsposition gibt.

Mistrals Gesamtfinanzierung seit der Gründung: fast 2,8 Milliarden Euro. Das zeigt: Trotz Regulierung investiert Europa in seine KI-Zukunft.

---

## Folie 16: Questions?

Vielen Dank für eure Aufmerksamkeit!

Habt ihr Fragen?
